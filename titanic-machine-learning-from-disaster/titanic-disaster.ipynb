{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Titanic: Machine Learning from Disaster</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "plt.rcParams['figure.figsize'] = (7, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ffdf3cd7ca6fe516a498d903989eeb8556c33843"
   },
   "outputs": [],
   "source": [
    "# Load and preview datasets \n",
    "train_dataset, test_dataset = pd.read_csv('data/train.csv'), pd.read_csv('data/test.csv')\n",
    "\n",
    "# Examine training and testing dataset shapes\n",
    "print('Training Dataset: %s, Testing Dataset: %s' %(str(train_dataset.shape), str(test_dataset.shape)))\n",
    "\n",
    "# Inspect column types\n",
    "train_dataset.dtypes.reset_index()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.head(3)  # Peek at the first 3 rows of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f6d594ac0102c59a1ef71164b9a90293df590944"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "05c2ce8eabebb2e59130af87755a4a72481864c2"
   },
   "outputs": [],
   "source": [
    "# Compare number of dead versus survived\n",
    "survivors = train_dataset[train_dataset['Survived'] == 1]['Pclass'].value_counts()\n",
    "dead = train_dataset[train_dataset['Survived'] == 0]['Pclass'].value_counts()\n",
    "df_survival_pclass = pd.DataFrame([survivors, dead])\n",
    "df_survival_pclass.index = ['Dead', 'Survived']\n",
    "df_survival_pclass.plot(kind='bar', stacked=True, title='Survival Based on by Passenger Class');\n",
    "train_dataset['Dead'] = 1 - train_dataset['Survived']\n",
    "train_dataset.groupby('Sex').agg('sum')[['Survived', 'Dead']].plot(kind='bar', stacked=True, colors=['g', 'r'], title='Survival Based on by Sex');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0947ea234bcbca10e76d54ee880fa70a950696bd"
   },
   "outputs": [],
   "source": [
    "def null_check(train_dataset, test_dataset):\n",
    "    \"\"\"Checks and returns a summary of null elements of the training and testing datasets.\"\"\"\n",
    "    print(\"Training Dataset:\")\n",
    "    print(train_dataset.isnull().sum())\n",
    "\n",
    "    print(\"\\nTesting Dataset:\")\n",
    "    print(test_dataset.isnull().sum())\n",
    "\n",
    "\n",
    "null_check(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "98a166a07fa0e2173f573ef6d1a01b36c9123936"
   },
   "source": [
    "## Data Wrangling, Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "93d21b91aeb38a25794b08da9339cf8dbe166dfa"
   },
   "outputs": [],
   "source": [
    "# Replace NaN values in the column 'Age' with the median value \n",
    "train_dataset['Age'] = train_dataset['Age'].fillna(train_dataset['Age'].median())\n",
    "test_dataset['Age'] = test_dataset['Age'].fillna(test_dataset['Age'].median())\n",
    "\n",
    "# Apply same concept as above\n",
    "train_dataset[\"Embarked\"].fillna(\"S\", inplace = True)\n",
    "test_dataset[\"Embarked\"].fillna(\"S\", inplace = True)\n",
    "train_dataset[\"Fare\"].fillna(train_dataset[\"Fare\"].median(), inplace = True)\n",
    "test_dataset[\"Fare\"].fillna(test_dataset[\"Fare\"].median(), inplace = True)\n",
    "\n",
    "# Drop columns 'Cabin' and 'Ticket' since they contain a lot of noise\n",
    "train_dataset.drop(labels = [\"Cabin\", \"Ticket\"], axis = 1, inplace = True)\n",
    "test_dataset.drop(labels = [\"Cabin\", \"Ticket\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "93d21b91aeb38a25794b08da9339cf8dbe166dfa"
   },
   "outputs": [],
   "source": [
    "encoder_embarked, encoder_sex, = LabelEncoder(), LabelEncoder()\n",
    "\n",
    "encoder_embarked.fit(train_dataset['Embarked'])\n",
    "encoder_sex.fit(train_dataset['Sex'])\n",
    "encoder_embarked.fit(test_dataset['Embarked'])\n",
    "encoder_sex.fit(test_dataset['Sex'])\n",
    "\n",
    "\n",
    "train_dataset['Embarked'] = encoder_embarked.transform(train_dataset['Embarked'])\n",
    "train_dataset['Sex'] = encoder_sex.transform(train_dataset['Sex'])\n",
    "test_dataset['Embarked'] = encoder_embarked.transform(test_dataset['Embarked'])\n",
    "test_dataset['Sex'] = encoder_sex.transform(test_dataset['Sex'])\n",
    "\n",
    "null_check(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e72a620b77de2b21e3e883292a874a5759de9ba0"
   },
   "outputs": [],
   "source": [
    "# Define the scaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = train_dataset[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']].values\n",
    "y_train = train_dataset['Survived'].values\n",
    "\n",
    "X_test = test_dataset[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']].values\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e48787c5ffbe10837039569ea0e3877fc1ca1d91"
   },
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [GradientBoostingClassifier(), LinearSVC(), RandomForestClassifier(), XGBClassifier()]\n",
    "for estimator in estimators:\n",
    "    print(str(estimator.__class__.__name__) + ': ' + str(cross_val_score(estimator, X_train, y_train, cv=10, scoring='accuracy').mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print list of parameters of selected classifier\n",
    "print(list(GradientBoostingClassifier().get_params().keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters = {'learning_rate': [1, 0.5, 0.25, 0.1, 0.05, 0.01],              \n",
    "              'max_depth': np.linspace(1, 32, 32, endpoint=True),\n",
    "              'min_samples_leaf': np.linspace(0.1, 0.5, 5, endpoint=True),\n",
    "              'min_samples_split': np.linspace(0.1, 1.0, 10, endpoint=True),\n",
    "              'n_estimators': [1, 2, 4, 8, 16, 32, 64, 100, 200]}\n",
    "\n",
    "hyper_model = GridSearchCV(GradientBoostingClassifier(), param_grid=parameters, scoring='roc_auc', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Parameters: ', hyper_model.best_params_)\n",
    "print('Mean Train Score: ', hyper_model.cv_results_['mean_train_score'])\n",
    "print('Mean Test Score: ', hyper_model.cv_results_['mean_test_score'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
